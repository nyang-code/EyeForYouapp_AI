{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc/anaconda3/envs/CPR_YOLO/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('/home/mmc/disk2/duck/cap/cnn/drink_2/RMBG_640/train/drink.csv')\n",
    "val_df = pd.read_csv('/home/mmc/disk2/duck/cap/cnn/drink_2/RMBG_640/val/drink.csv')\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "print(f'train shape: {train_df.shape}\\nval shape: {val_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelDropout(object):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        mask = torch.rand_like(img) > self.dropout_prob\n",
    "        img = img * mask\n",
    "        return img\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx]['path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels.iloc[idx]['class']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    # transforms.RandomApply([transforms.RandomResizedCrop((224, 224))], p=0.3),\n",
    "    # transforms.RandomHorizontalFlip(),  # 좌우 반전\n",
    "    # transforms.RandomRotation(10),  # 30도 이내의 무작위 회전\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # 밝기, 대비, 채도, 색조 변화\n",
    "    transforms.ToTensor(),\n",
    "    # PixelDropout(dropout_prob=0.1),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 사용자 정의 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomImageDataset(train_df,transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = CustomImageDataset(val_df, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomImageClassifier, self).__init__()\n",
    "        self.base_model = timm.create_model('resnet50.a1_in1k', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = F.softmax(x, dim=1)  # 소프트맥스 적용\n",
    "        return x\n",
    "\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "model = CustomImageClassifier(num_classes)\n",
    "\n",
    "# 저장된 가중치를 로드합니다.\n",
    "# model.load_state_dict(torch.load('./snack_pt_0518_resnet18/last_0.033.pt'))\n",
    "\n",
    "# 모델을 적절한 장치로 이동시킵니다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 초기 최소 검증 손실값 설정\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "# 학습 및 검증 과정\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(100): \n",
    "    model.train()\n",
    "    train_loss, val_loss = 0.0, 0.0\n",
    "    \n",
    "    # 학습 부분\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 검증 부분\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # 에폭별 손실 출력\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # 검증 손실이 개선되었는지 확인하고 모델 저장\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), './kang/snack_pt/best.pt')\n",
    "        print(f\"Model saved: Epoch {epoch+1} with Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # # 5 에폭마다 손실값 시각화\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "        \n",
    "    #     plt.figure(figsize=(10, 5))\n",
    "    #     plt.plot(range(1, epoch+2), train_losses, label='Train Loss')\n",
    "    #     plt.plot(range(1, epoch+2), val_losses, label='Validation Loss')\n",
    "    #     plt.xlabel('Epoch')\n",
    "    #     plt.ylabel('Loss')\n",
    "    #     plt.title('Train and Validation Loss')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True)\n",
    "    #     plt.savefig(f'./snack_pt_0520_resnet18/loss_plot_epoch_{epoch+1}.png')\n",
    "    #     plt.show()\n",
    "\n",
    "# 마지막 모델 상태 저장\n",
    "torch.save(model.state_dict(), f'./snack_pt_0520_resnet18/last_{min_val_loss:.2f}.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPR_YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
